{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet Lab\n",
    "\n",
    "![](image/lenet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/car2/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/root/anaconda3/envs/car2/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/root/anaconda3/envs/car2/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('.', reshape=False)\n",
    "\n",
    "train_features, train_labels = mnist.train.images, mnist.train.labels\n",
    "validation_features, validation_labels = mnist.validation.images, mnist.validation.labels\n",
    "test_features, test_labels = mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST data in 28x28x1, but LeNet accepts 32x32xC images, so we need to pad data with zeros, 2 for each side. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "train_features = np.pad(train_features, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "validation_features = np.pad(validation_features, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "test_features = np.pad(test_features, ((0,0),(2,2),(2,2),(0,0)), 'constant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAABgxJREFUeJztnE1oXFUUx3+nVTfRhW2iDdpGEUmabmojbiQhXQjWTTKFiIUKgjS2UGobQdOEgpCmDRiztSS10IUgQlJwUUiLKKUbmxqKOk2rRSSphsmHC6tdyMwcF+/d6SSddj7ezJ2Zl/uDx7x5X/fM/5137sc7c0VVcdhhXbkNWEs4sS3ixLaIE9siTmyLOLEt4sS2SCCxReR1EbkpIrdEpLdYRoUVKbRTIyLrgV+A14DbwBSwR1WvF8+8cPFIgHNfAW6p6m8AIvIl0AE8UGwRCW13VVUl2zFBwsgzwFza99v+thWISLeIXBWRqwHKCgVBPDvTnbzPc1V1FBiFcHt2LgTx7NvA5rTvzwJ/BjMn3AQRewp4UUSeF5HHgLeAr4tjVjgpOIyoalxEDgKTwHrgjKpGi2ZZCCm46VdQYSGO2bm0RoJUkFVBTU0NAL29Xp+rubmZzs5OAHbu3AnApUuXrNjiuusWCa1nNzU1ATA+Pg5AY2MjACLC9etevyuZTNo1SlWtLXjt8JIvAwMDmkgkNJFIaDKZ1GQyqdFoVKPRqDY1NZWkzFx+vwsjFglVGOnv7wegr6/PPEmcOHECgJMnTwJw9+7d8hiHqyCtEop29pEjRwAYHh4GYG5ujr179wJw+fLlUhR5H7m0s6u+goxEIhqLxTQWi2k8Htd4PK6RSMRKRZy+uAqywqjaMGJ6hleuXGHr1q0ADA4OAnDs2LFiFZMzpX554MiTqm36mbGOxsZGFhcXARgbGyunSVlxnm2RqvXs5uZmwBvrMDF6dna2nCZlpWoryEQiAXhN102bNgGwtLRUrMvnjasgK4yqCyNtbW2AFz7AG/sop0fng/Nsi1SdZx89ehQgNap37ty5vM7v7u5OrZsmY77XKJSqEbuhoQGAHTt2AHDhwgUApqen7zu2pqYm9abGhB3TLq+rq0vdKBOKZmZmAGhvb0/dgFLgwohFqsaza2trAdi4cSOQ+dE33jw4OEhHRwdwz3vNe8fR0dHU8WZMxbxtP3/+PLt27QJK04x0nm2RqvHs1U2+dFpaWgAYGRkBoLW1NRV79+/fD2R+Eurq6lac39LSwpYtW4AyebaIbBaRb0VkRkSiIvK+v32DiFwUkV/9zyeLbl3IyMWz48AHqjotIk8AP4jIReAd4BtVHfL/4tELfFQqQ03ex+rhhf7+fg4dOgTci+cTExP09PQADx8vMd5v4vjx48eLa/QqsoqtqvPAvL9+R0Rm8JLeO4B2/7CzwHeUUGwjjAkjp06dMval3ph3dXUB+bebd+/eDcC6daWtwvKK2SLyHPAS8D3wtH8jUNV5EXnqAed0A92Z9q01chZbRB4HxoHDqvp3pooqE8X658Hp06cB2LdvH3CvclPVVG5Ivh5t8kxMk3FhYaGk4yw5PTci8iie0F+o6oS/OSYi9f7+emChNCaGh6zj2eK58FngL1U9nLb9E2A5rYLcoKofZrlW4PFs440DAwOA59nmKZuY8PxgaGgo1YkxLxnM72xra0t1YlpbW1fs27ZtGzdu3CjIrmLlZ78KvA38JCLX/G19wBDwlYi8C8wCXQVZuYaomjc1Jq5OTU0BMDk5CXhNwtXem54WnGmfWV9eXl6x78CBAwWPAObi2VUjdqXjXotVGE5sizixLeLEtogT2yJObIs4sS3ixLaIE9siTmyLOLEt4sS2iBPbIrbzRpaAf/3PSqeW3O1syOUgq0OsACJyVVVftlpoAZTCThdGLOLEtkg5xB7NfkhFUHQ7rcfstYwLIxaxJnYlz7X9kEzdj0XkDxG55i9vBCrHRhip9Lm2/Yyu+vRMXaATeBP4R1WHi1GOLc9OzbWtqv8BZq7tikBV51V12l+/A5hM3aJiS+yc5tquBFZl6gIcFJEfReRM0IR/W2LnNNd2uVmdqQt8BrwAbMfLUf80yPVtiV3xc21nytRV1ZiqJlQ1CYzhhcOCsSV2Rc+17Wfqfg7MqOpI2vb6tMMiwM9ByrEy6qeVP9f2gzJ194jIdryQ9zvwXpBCXA/SIq4HaREntkWc2BZxYlvEiW0RJ7ZFnNgWcWJb5H/gNH1i/2Ij2wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f08aaecb0b8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "\n",
    "index = random.randint(0, len(train_features))\n",
    "image = train_features[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "print(train_labels[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement LeNet-5\n",
    "Implement the [LeNet-5](http://yann.lecun.com/exdb/lenet/) neural network architecture.\n",
    "\n",
    "### Input\n",
    "The LeNet architecture accepts a 32x32xC image as input, where C is the number of color channels. Since MNIST images are grayscale, C is 1 in this case.\n",
    "\n",
    "### Architecture\n",
    "**Layer 1: Convolutional.** The output shape should be 28x28x6.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 14x14x6.\n",
    "\n",
    "**Layer 2: Convolutional.** The output shape should be 10x10x16.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 5x5x16.\n",
    "\n",
    "**Flatten.** Flatten the output shape of the final pooling layer such that it's 1D instead of 3D. The easiest way to do is by using `tf.contrib.layers.flatten`, which is already imported for you.\n",
    "\n",
    "**Layer 3: Fully Connected.** This should have 120 outputs.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Layer 4: Fully Connected.** This should have 84 outputs.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Layer 5: Fully Connected (Logits).** This should have 10 outputs.\n",
    "\n",
    "### Output\n",
    "Return the result of the 2nd fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "\n",
    "# arguments for random normal distribution for initializing weights\n",
    "mu = 0\n",
    "sigma = 0.1\n",
    "\n",
    "weights = {\n",
    "    'conv1': tf.Variable(tf.truncated_normal([5,5,1,6], mean=mu, stddev=sigma), name=\"weights_1\"),\n",
    "    'conv2': tf.Variable(tf.truncated_normal([5,5,6,16], mean=mu, stddev=sigma), name=\"weights_2\"),\n",
    "    'fc1': tf.Variable(tf.truncated_normal([400, 120], mean=mu, stddev=sigma)),\n",
    "    'fc2': tf.Variable(tf.truncated_normal([120, 84], mean=mu, stddev=sigma)),\n",
    "    'out': tf.Variable(tf.truncated_normal([84, 10], mean=mu, stddev=sigma))\n",
    "}\n",
    "\n",
    "\n",
    "def LeNet(input_data):\n",
    "    \n",
    "    biases = {\n",
    "        'conv1': tf.Variable(tf.truncated_normal([6])),\n",
    "        'conv2': tf.Variable(tf.truncated_normal([16])),\n",
    "        'fc1': tf.Variable(tf.truncated_normal([120])),\n",
    "        'fc2': tf.Variable(tf.truncated_normal([84])),\n",
    "        'out': tf.Variable(tf.truncated_normal([10]))\n",
    "    }\n",
    "    \n",
    "    pool_size = [1,2,2,1]\n",
    "    conv_strides = [1,1,1,1]\n",
    "    \n",
    "    # Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    Z1 = tf.nn.conv2d(input_data, weights['conv1'], strides=conv_strides, padding='VALID')\n",
    "    Z1 = tf.nn.bias_add(Z1, biases['conv1'])\n",
    "\n",
    "    # Activation.\n",
    "    A1 = tf.nn.sigmoid(Z1)\n",
    "\n",
    "    # Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    P1 = tf.nn.max_pool(A1, ksize=pool_size, strides=pool_size, padding='SAME')\n",
    "\n",
    "    # Layer 2: Convolutional. Output = 10x10x16.\n",
    "    Z2 = tf.nn.conv2d(P1, weights['conv2'], strides=conv_strides, padding='VALID')\n",
    "    Z2 = tf.nn.bias_add(Z2, biases['conv2'])\n",
    "    \n",
    "    # Activation.\n",
    "    A2 = tf.nn.sigmoid(Z2)\n",
    "\n",
    "    # Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    P2 = tf.nn.max_pool(A2, ksize=pool_size, strides=pool_size, padding='SAME')\n",
    "\n",
    "    # Flatten. Input = 5x5x16. Output = 400.\n",
    "    flat = flatten(P2)\n",
    "    \n",
    "    # Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    FC1 = tf.add(tf.matmul(flat, weights['fc1']), biases['fc1'])\n",
    "    \n",
    "    # Activation.\n",
    "    A3 = tf.nn.sigmoid(FC1)\n",
    "\n",
    "    # Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    FC2 = tf.add(tf.matmul(A3, weights['fc2']), biases['fc2'])\n",
    "    \n",
    "    # Activation.\n",
    "    A4 = tf.nn.sigmoid(FC2)\n",
    "\n",
    "    # Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    "    logits = tf.add(tf.matmul(A4, weights['out']), biases['out'])\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Labels\n",
    "Train LeNet to classify [MNIST](http://yann.lecun.com/exdb/mnist/) data.\n",
    "\n",
    "`x` is a placeholder for a batch of input images.\n",
    "`y` is a placeholder for a batch of output labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32,32,1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .001\n",
    "\n",
    "logits = LeNet(x)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate With Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 Validation Accuracy = 0.851\n",
      "EPOCH 2 Validation Accuracy = 0.943\n",
      "EPOCH 3 Validation Accuracy = 0.961\n",
      "EPOCH 4 Validation Accuracy = 0.969\n",
      "EPOCH 5 Validation Accuracy = 0.976\n",
      "EPOCH 6 Validation Accuracy = 0.978\n",
      "EPOCH 7 Validation Accuracy = 0.980\n",
      "EPOCH 8 Validation Accuracy = 0.982\n",
      "EPOCH 9 Validation Accuracy = 0.983\n",
      "EPOCH 10 Validation Accuracy = 0.985\n",
      "EPOCH 11 Validation Accuracy = 0.987\n",
      "EPOCH 12 Validation Accuracy = 0.986\n",
      "EPOCH 13 Validation Accuracy = 0.984\n",
      "EPOCH 14 Validation Accuracy = 0.986\n",
      "EPOCH 15 Validation Accuracy = 0.987\n",
      "EPOCH 16 Validation Accuracy = 0.989\n",
      "EPOCH 17 Validation Accuracy = 0.989\n",
      "EPOCH 18 Validation Accuracy = 0.988\n",
      "EPOCH 19 Validation Accuracy = 0.989\n",
      "EPOCH 20 Validation Accuracy = 0.989\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        train_features, train_labels = shuffle(train_features, train_labels)\n",
    "        for batch_start in range(0, len(train_features), BATCH_SIZE):\n",
    "            batch_end = batch_start+BATCH_SIZE\n",
    "            batch_x, batch_y = train_features[batch_start:batch_end], train_labels[batch_start:batch_end]\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y:batch_y})\n",
    "            \n",
    "        valid_acc = sess.run(accuracy, feed_dict={x: validation_features, y: validation_labels})\n",
    "        print(\"EPOCH {} Validation Accuracy = {:.3f}\".format(epoch+1, valid_acc))\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./lenet\n",
      "Test Accuracy = 0.988\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    \n",
    "    test_acc = sess.run(accuracy, feed_dict={x: test_features, y: test_labels})\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_image: fed into network to produce the feature maps \n",
    "# tf_activation: tf variable name used during training that rep specific weight layer\n",
    "# to get tf_activation, session should be interactive:\n",
    "# sess = tf.InteractiveSession()\n",
    "# sess.as_default()\n",
    "\n",
    "# activation_min/max: can be used to view the activation contrast in more detail, \n",
    "# by default matplot sets min and max to the actual min and max values of the output\n",
    "\n",
    "# plt_num: used to plot out multiple different weight feature map sets, a unique identifier for the pyplot figure.\n",
    "\n",
    "\n",
    "def outputFeatureMap(image_input, tf_activation, activation_min=None, activation_max=None, plt_num=1):\n",
    "    activation = tf_activation.eval(session=sess)\n",
    "    featuremaps = activation.shape[3]\n",
    "    plt.figure(plt_num, figsize=(15,15))\n",
    "    for featuremap in range(featuremaps):\n",
    "        plt.subplot(6,8, featuremap+1)\n",
    "        if activation_min is not None and activation_max is not None:\n",
    "            plt.imshow(activation[0,:,:,featuremap], interpolation=\"nearest\", vmin=activation_min, vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_min is not None:\n",
    "            plt.imshow(activation[0,:,:,featuremap], interpolation=\"nearest\", vmin=activation_min, cmap=\"gray\")\n",
    "        elif activation_max is not None:\n",
    "            plt.imshow(activation[0,:,:,featuremap], interpolation=\"nearest\", vmax=activation_max, cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(activation[0,:,:,featuremap], interpolation=\"nearest\", cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:car2]",
   "language": "python",
   "name": "conda-env-car2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
