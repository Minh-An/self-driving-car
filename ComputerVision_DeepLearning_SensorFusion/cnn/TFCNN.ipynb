{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 64\n",
    "\n",
    "img_size = [10,10,3]\n",
    "\n",
    "filter_size = [5,5]\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# image \n",
    "input_img = tf.placeholder(tf.float32, shape=[None, *img_size])\n",
    "\n",
    "# weight + bias\n",
    "weight = tf.Variable(tf.truncated_normal([*filter_size, img_size[2], k]))\n",
    "bias = tf.Variable(tf.zeros(k))\n",
    "\n",
    "# hyperparams\n",
    "strides = [1,2,2,1]\n",
    "padding = 'SAME'\n",
    "\n",
    "# apply convolution \n",
    "conv_layer = tf.nn.conv2d(input_img, weight, strides=strides, padding=padding)\n",
    "# add bias\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "# apply activation\n",
    "conv_layer = tf.nn.relu(conv_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Max Pooling \n",
    "\n",
    "![max](image/max-pooling.png)\n",
    "\n",
    "The image above is an example of max pooling with a 2x2 filter and stride of 2. The four 2x2 colors represent each time the filter was applied to find the maximum value.\n",
    "\n",
    "Benefit of max pooling is to reduce size of the input and allows CNN to focus on only the most important elements (hence retaining only the max value for each filtered area and removing the rest) \n",
    "\n",
    "TF provides `tf.nn.max_pool()` function to apply max pooling to conv layers.\n",
    "\n",
    "Parameters: \n",
    "\n",
    "- `ksize` size of the filter `[1,2,2,1]` is common\n",
    "- `strides` `[1,2,2,1]` is common\n",
    "- `padding` \n",
    "\n",
    "First and last dimensions in the ksize/stride array are for `batch` and `channels`, and are usually set to `1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = tf.nn.max_pool(\n",
    "    conv_layer,\n",
    "    ksize = [1,2,2,1],\n",
    "    strides = [1,2,2,1],\n",
    "    padding = 'SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Example CNN in TensorFlow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters \n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "batch_size = 128\n",
    "\n",
    "# Samples for validation and test sets \n",
    "test_valid_size = 256\n",
    "\n",
    "# Network params\n",
    "num_classes = 10\n",
    "dropout = .75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'conv1': tf.Variable(tf.random_normal([5,5,1,32])),\n",
    "    'conv2': tf.Variable(tf.random_normal([5,5,32,64])),\n",
    "    'fc1': tf.Variable(tf.random_normal([7*7*64,1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, num_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'conv1': tf.Variable(tf.random_normal([32])),\n",
    "    'conv2': tf.Variable(tf.random_normal([64])),\n",
    "    'fc1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutions\n",
    "\n",
    "![](image/convolution-schematic.gif)\n",
    "\n",
    "Convolution w/ 3x3 filter and stride of 1 being applied to data.\n",
    "\n",
    "The convolution for each 3x3 section is calculated against the weight, `[[1, 0, 1], [0, 1, 0], [1, 0, 1]]`, then a bias is added to create the convolved feature on the right. In this case, the bias is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, stride = 1, padding='SAME'):\n",
    "    hidden = tf.nn.conv2d(x, W, strides=[1,stride,stride,1], padding=padding)\n",
    "    hidden = tf.nn.bias_add(hidden, b)\n",
    "    return tf.nn.relu(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Pooling\n",
    "\n",
    "![](image/maxpool.jpeg)\n",
    "\n",
    "Max pooling with 2x2 filter and a stride of 2. The colors in put represent each time the filter was applied to create the max on the right. \n",
    "\n",
    "For example, `[[1, 1], [5, 6]]` becomes 6 and `[[3, 2], [1, 2]]` becomes 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d(conv, size=2):\n",
    "    return tf.nn.max_pool(\n",
    "        conv,\n",
    "        ksize=[1,size,size,1],\n",
    "        strides=[1,size,size,1],\n",
    "        padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "![](image/arch.png)\n",
    "\n",
    "We're going to create 3 layers alternating b/w convs and max pooling followed by a fully connected and output layer. The transformation with the new dimensions are shown in the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(input_data, weights, biases, dropout):\n",
    "    # Layer 1 - 28x28x1 to 14x14x32\n",
    "    conv1 = conv2d(input_data, weights['conv1'], biases['conv1'])\n",
    "    conv1 = maxpool2d(conv1, size=2)\n",
    "    \n",
    "    # Layer 2 - 14x14x32 to 7x7x64\n",
    "    conv2 = conv2d(conv1, weights['conv2'], biases['conv2'])\n",
    "    conv2 = maxpool2d(conv2, size=2)\n",
    "    \n",
    "    # FC layer - 7x7x64 to 1024\n",
    "    flat_dim = weights['fc1'].get_shape().as_list()[0] #7x7x64\n",
    "    fc1 = tf.reshape(conv2, [-1, flat_dim])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['fc1']), biases['fc1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "    \n",
    "    # output layer - 1024 to 10\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# model \n",
    "logits = conv_net(x, weights, biases, dropout)\n",
    "\n",
    "# loss, optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "import math\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        num_batches = math.ceil(mnist.train.num_examples/batch_size)\n",
    "        for batch in range(num_batches):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "            \n",
    "        loss = sess.run(cost, feed_dict={\n",
    "            x: batch_x,\n",
    "            y: batch_y,\n",
    "            keep_prob: 1.})\n",
    "        valid_accuracy = sess.run(accuracy, feed_dict={\n",
    "            x: mnist.validation.images,\n",
    "            y: mnist.validation.labels,\n",
    "            keep_prob: 1.})\n",
    "\n",
    "        print('Epoch {} Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(epoch, loss, valid_accuracy))\n",
    "            \n",
    "    test_accuracy = sess.run(accuracy, feed_dict={\n",
    "        x: mnist.test.images,\n",
    "        y: mnist.test.labels,\n",
    "        keep_prob: 1.})\n",
    "\n",
    "    print('Test Accuracy: {:.6f}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:car2]",
   "language": "python",
   "name": "conda-env-car2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
